{% extends "base.html" %} {% block title %}Image Forgery Detection - About{%
endblock %} {% block content %}
<section class="about-hero py-5">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 mx-auto text-center">
        <h1 class="display-4 fw-bold mb-4">About the Project</h1>
        <p class="lead">
          Learn about our image forgery detection system, how it works, and the
          technology behind it.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="about-content py-5">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 mx-auto">
        <div class="card shadow-sm mb-5">
          <div class="card-body p-4">
            <h2 class="mb-4">Project Overview</h2>
            <p>
              This project implements a Convolutional Neural Network (CNN) for
              the purpose of extracting features in the problem of image forgery
              detection. The approach is inspired by the work of Y. Rao et al.
              "A Deep Learning Approach to Detection of Splicing and Copy-Move
              Forgeries in Images".
            </p>
            <p>
              Following the feature fusion proposed in the same paper, we take
              the extracted features and give them as input to an SVM that
              performs the final binary classification task. The SVM
              implementation was taken from scikit-learn.
            </p>
            <p>
              The datasets used in this project are the CASIA2 and the NC2016
              datasets. This study was conducted as a final project of TU
              Delft's course CS4180 Deep Learning.
            </p>
          </div>
        </div>

        <div class="card shadow-sm mb-5">
          <div class="card-body p-4">
            <h2 class="mb-4">System Pipeline</h2>
            <p>The pipeline of the system consists of three main steps:</p>
            <ol>
              <li class="mb-3">
                <strong>CNN Training:</strong> Train the CNN with image patches
                close to the distribution of the images that the network will
                work on. The training patches contain both tampered and
                untampered regions from the corresponding images.
              </li>
              <li class="mb-3">
                <strong>Feature Extraction:</strong> Extract features from
                unseen images by breaking them into patches and applying feature
                fusion after the final convolutional layer of the network.
              </li>
              <li class="mb-3">
                <strong>SVM Classification:</strong> Use an SVM classifier on
                the 400 extracted features of the previous step for the final
                classification.
              </li>
            </ol>
          </div>
        </div>

        <div class="card shadow-sm mb-5">
          <div class="card-body p-4">
            <h2 class="mb-4">Network Architecture</h2>
            <p>
              The CNN architecture of this project is influenced by the work of
              Y. Rao et al. The network structure is:
            </p>
            <ul>
              <li>2 convolutions</li>
              <li>Max pooling</li>
              <li>4 convolutions</li>
              <li>Max pooling</li>
              <li>3 convolutions</li>
            </ul>
            <p>
              In the training phase, after the final convolution, a fully
              connected layer with softmax is applied. In the testing phase, the
              400-D output of the final convolutional layer is used in the next
              Feature Fusion step that creates the feature vectors.
            </p>
          </div>
        </div>

        <div class="card shadow-sm mb-5">
          <div class="card-body p-4">
            <h2 class="mb-4">Results</h2>
            <p>
              The SVM classification accuracy on both datasets after the 10-fold
              cross-validation is:
            </p>
            <div class="table-responsive">
              <table class="table table-bordered">
                <thead class="table-light">
                  <tr>
                    <th>Dataset</th>
                    <th>Accuracy</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>CASIA2</td>
                    <td>96.82% ± 1.19%</td>
                  </tr>
                  <tr>
                    <td>NC2016</td>
                    <td>84.89% ± 6.06%</td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
        </div>

        <div class="card shadow-sm">
          <div class="card-body p-4">
            <h2 class="mb-4">Team Members</h2>
            <ul class="list-unstyled">
              <li class="mb-2">
                <i class="fas fa-user me-2"></i> Prithwiraj Solunke
              </li>
              <li class="mb-2">
                <i class="fas fa-user me-2"></i> Omkar Kharmare
              </li>
              <li class="mb-2">
                <i class="fas fa-user me-2"></i> Gaurav Ghadage
              </li>
            </ul>
            <div class="mt-4">
              <a
                href="https://github.com/prithwirajsolunke/Image-Forgery-Detection-CNN"
                target="_blank"
                class="btn btn-outline-primary"
              >
                <i class="fab fa-github me-2"></i>View on GitHub
              </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
{% endblock %}
